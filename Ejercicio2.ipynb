{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "equal-gender",
   "metadata": {},
   "source": [
    "Ejercicio 2\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "powered-wayne",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "#constantes usadas durante este ejercicio cuyos valores se han decidido después de un estudio de los datos\n",
    "IMG_SIZE = 224\n",
    "NUM_CLASSES = 5\n",
    "BATCH_SIZE = 32\n",
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-corpus",
   "metadata": {},
   "source": [
    "Para comenzar cargamos los datos directamente desde keras usando la función load predefinida. Con:\n",
    "    - as_supervised le decimos que nos descargue también las etiquetas, \n",
    "    - con split le indicamos que nos divida ya directamente el conjunto de datos en train, validation y test \n",
    "    (las proporciones dadas por defecto en el ejercicio son adecuadas para tales conjuntos)\n",
    "    - con  shuffle_files le pedimos que nos mezcle los datos. \n",
    "    Siempre es importante mezclar los datos (siempre y cuando sean sean independientes unos ejemplos de otros) \n",
    "        para evitar sobreentrenamientos o una representación no adecuada (por ejemplo un train con la mayoría \n",
    "              de ejemplos de un tipo y apenas de otro).\n",
    "    - definimos el batch_size por defecto a 32, que es un tamaño adecuado para estos problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pleased-victim",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load this dataset in directly in memory using tfds as follows:\n",
    "\"\"\"\n",
    "(train_datasets, val_ds, test_ds), metadata = tfds.load(\n",
    "    'tf_flowers',\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    "    shuffle_files = True,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-stuff",
   "metadata": {},
   "source": [
    "Lo primero es necesario hacer un estudio del conjunto de datos, familiarizarse con el problema y observar sus características. Conviene calcular estadísticas, visualizar algunas imágenes, comprobar si nos topamos con \"labels\" y ver en qué formato vienen definidas.\n",
    "\n",
    "En este caso en concreto, nos encontramos un con conjunto de datos relativamente balanceado pero no muchos ejemplos. Tenemos 5 clases que corresponden a los 5 tipos diferentes de flor que vienen codificadas de 0 a 4 en la etiqueta label.\n",
    "\n",
    "También es recomendable para estudiar el data set visualizar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "exact-austin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='tf_flowers',\n",
      "    full_name='tf_flowers/3.0.1',\n",
      "    description=\"\"\"\n",
      "    A large set of images of flowers\n",
      "    \"\"\",\n",
      "    homepage='https://www.tensorflow.org/tutorials/load_data/images',\n",
      "    data_path='/home/users/rpierrard/tensorflow_datasets/tf_flowers/3.0.1',\n",
      "    download_size=218.21 MiB,\n",
      "    dataset_size=221.83 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(None, None, 3), dtype=tf.uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=5),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'train': <SplitInfo num_examples=3670, num_shards=2>,\n",
      "    },\n",
      "    citation=\"\"\"@ONLINE {tfflowers,\n",
      "    author = \"The TensorFlow Team\",\n",
      "    title = \"Flowers\",\n",
      "    month = \"jan\",\n",
      "    year = \"2019\",\n",
      "    url = \"http://download.tensorflow.org/example_images/flower_photos.tgz\" }\"\"\",\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#list(train_datasets.as_numpy_iterator())\n",
    "print(metadata)#Vamos a imprimir un poco de información sobre el conjunto de datos que acabamos de leer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-thesaurus",
   "metadata": {},
   "source": [
    "Una vez completados los pasos previos, procedemos a la etapa de preprocesamiento de los datos. En ella he realizado dos tareas:\n",
    "\n",
    "1- resize_normalize: dado que voy a trabajar con CNN (que es la arquitectura de NN más recomendable y desarrollada para procesamiento de imágenes), las imágenes de entrada para el entrenamiento y test deben tener el mismo tamaño. Es muy recomendable normalizar dichas imágenes pues la definición matemática de estos modelos tolera y reacciona mejor a numéros pequeños que a grandes cantidades. \n",
    "Codificamos con one hot encoder la label de cada imagen para que tome como formato de salida un array de 5 posiciones\n",
    "\n",
    "2- augmentation: en computer vision siempre es una técnica importante para entrenar modelos robustos. Evita el overfitting y ayuda al modelo a extraer mejor las features (características) únicas de las clases en el conjunto de datos. \n",
    "\n",
    "Mejoras:\n",
    "------------\n",
    "Por falta de tiempo no he podido implementar todo lo que me hubiera gustado. En este punto por ejemplo añadiría la función de generación de imágenes con perturbaciones para crear imágenes adversariales que agregaría a los conjunto de datos.\n",
    "También añadiría más técnicas de data augmentation para generar nuevas imágenes las cuales añadiría a los conjuntos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "tested-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_normalize(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    # Normalize the pixel values\n",
    "    image = image / 255.0\n",
    "    # Resize the image\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    label = tf.one_hot(label,5)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def augmentation(image, label):  \n",
    "  image = tf.image.random_flip_left_right(image)  \n",
    "  image = tf.image.random_contrast(image, lower=0.0, upper=1.0)  \n",
    "  return image,label\n",
    "\n",
    "#poner la generación de imágenes adversariales desarrolado en el ejercicio 1\n",
    "\n",
    "train = train_datasets.map(resize_normalize)\n",
    "train = train.map(augmentation) #to improve the model we can consider applying on the fly augmentations instead of generating augmented dataset\n",
    "validation = val_ds.map(resize_normalize)\n",
    "test = test_ds.map(resize_normalize)\n",
    "\n",
    "#len(list(train.as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-flashing",
   "metadata": {},
   "source": [
    "Aquí viene la parte interesante. ¿Qué arquitectura elegimos?, ¿cómo entrenamos?\n",
    "\n",
    "Tenemos 2 opciones:\n",
    "    1- generar una arquitectura por nuestra cuenta desde cero, entrenarla en un conjunto rico de datos y dedicar mucho tiempo y recursos a mejorarla.\n",
    "    2- Emplear un modelo bueno ya pre-entrenado sobre un gran conjunto de imágenes (imagenet). Hoy en día se usa mucho esta opción: se escoje un modelo pre-entrenado (en datos similares) como extractor de características y se tunea (fine tuning) usando nuestro conjunto de datos\n",
    "    \n",
    "Por desgracia no dispongo de ninguna GPU, luego haber optado por la primera opción me habría llevado días, semanas... Por lo tanto he decidido utilizar la arquitectura propuesta en el ejercicio 1 (mobileNetV2) como extractor de características. Un modelo más complejo como extractor de características hubiera dado mejores resultados, pero dado que sólo tengo unas horas para hacer este test, he escogido mobileNetV2 al ser un modelo más ligeros (diseñado para dispositivos móviles) y que tarda menos tiempo en operar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-davis",
   "metadata": {},
   "source": [
    "Definimos algunas métricas que keras no tiene disponibles para evaluar nuestros resultados y proceso de aprendizaje: el recall, precision y f1 (ver wikipedia para más detalles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adaptive-protection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-maintenance",
   "metadata": {},
   "source": [
    "Ahora vamos a generar el modelo y entrenarlo (mirar por favor comentarios en el código):\n",
    "\n",
    "1) Generamos el extractor de características mobilNet2 y congelamos los pesos, el extractor de caracteristicas no lo vamos a entrenar. include_top=False nos devuelve únicamente el extractor y no el clasificador al completo como en el ejercicio 1.\n",
    "\n",
    "2) Generamos un modelo con varias capas: \n",
    "    - extractor de características pre-entrenado (mobilNetV2)\n",
    "    - una capa con una convolución2D y activación relu (usada en convoluciones)\n",
    "    - un dropout como técnica de regularización (para evitar el overfitting)\n",
    "    - una dense layer con función softmax que contenga 5 salidas. Cada una dará como resultado el intervalo de confianza que la red tiene al determinar que la imagen pertenece a la clase correspondiente a dicha salida (por ello se ha utilizado el one hot encoder para codificar las labels).\n",
    "    \n",
    "3) Después compilamos el modelo usando varias métricas definidas previamente, así como la loss y el accuracy.\n",
    "    He usado el optimizador ADAM pues es uno de los que mejor se comporta en estos casos. Ajusta la tasa de aprendizaje durante el mismo y usa el momentum para suavizar el descenso del gradiente. He escogido una learning rate de 0.0001 en lugar de 0.001 (que viene por defecto) pues parto de una red ya entrenada en extracción de características, nos interesa que el proceso de aprendizaje no experimente variaciones bruscas pues ya partimos de una buena base gracias a mobilNetV2.\n",
    "\n",
    "4) Establecemos 50 epochs. También habilitamos la funcionalidad de checkpoints para guardar modelso intermedios que se generen durante el entrenamiento y que puedan ser más satisfactorios.\n",
    "\n",
    "5) Entrenamos usando nuestros conjuntos de de train y validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "closing-swiss",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 5, 5, 32)          368672    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 2,626,821\n",
      "Trainable params: 368,837\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "92/92 [==============================] - 13s 109ms/step - loss: 1.2472 - acc: 0.4791 - f1_m: 0.3859 - precision_m: 0.6179 - recall_m: 0.3057 - val_loss: 0.5321 - val_acc: 0.8202 - val_f1_m: 0.7971 - val_precision_m: 0.8862 - val_recall_m: 0.7274\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.53206, saving model to ./model/model-001-0.592643-0.532060.h5\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.6656 - acc: 0.7408 - f1_m: 0.7244 - precision_m: 0.8229 - recall_m: 0.6620 - val_loss: 0.4850 - val_acc: 0.8447 - val_f1_m: 0.8377 - val_precision_m: 0.8900 - val_recall_m: 0.7936\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.53206 to 0.48502, saving model to ./model/model-002-0.740804-0.485019.h5\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 9s 96ms/step - loss: 0.5831 - acc: 0.7780 - f1_m: 0.7637 - precision_m: 0.8265 - recall_m: 0.7166 - val_loss: 0.4342 - val_acc: 0.8610 - val_f1_m: 0.8557 - val_precision_m: 0.8838 - val_recall_m: 0.8300\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.48502 to 0.43416, saving model to ./model/model-003-0.770777-0.434157.h5\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 9s 96ms/step - loss: 0.5734 - acc: 0.7791 - f1_m: 0.7502 - precision_m: 0.8539 - recall_m: 0.7068 - val_loss: 0.4159 - val_acc: 0.8556 - val_f1_m: 0.8565 - val_precision_m: 0.8854 - val_recall_m: 0.8297\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.43416 to 0.41591, saving model to ./model/model-004-0.775886-0.415909.h5\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 9s 96ms/step - loss: 0.5118 - acc: 0.8094 - f1_m: 0.7974 - precision_m: 0.8507 - recall_m: 0.7568 - val_loss: 0.4295 - val_acc: 0.8665 - val_f1_m: 0.8721 - val_precision_m: 0.8980 - val_recall_m: 0.8483\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.41591\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.4832 - acc: 0.8236 - f1_m: 0.8008 - precision_m: 0.8829 - recall_m: 0.7516 - val_loss: 0.4307 - val_acc: 0.8719 - val_f1_m: 0.8657 - val_precision_m: 0.8875 - val_recall_m: 0.8457\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.41591\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 9s 96ms/step - loss: 0.4171 - acc: 0.8540 - f1_m: 0.8311 - precision_m: 0.8751 - recall_m: 0.7955 - val_loss: 0.4556 - val_acc: 0.8828 - val_f1_m: 0.8727 - val_precision_m: 0.8909 - val_recall_m: 0.8557\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.41591\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.4293 - acc: 0.8500 - f1_m: 0.8306 - precision_m: 0.8889 - recall_m: 0.7865 - val_loss: 0.4284 - val_acc: 0.8692 - val_f1_m: 0.8661 - val_precision_m: 0.8859 - val_recall_m: 0.8483\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.41591\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.3986 - acc: 0.8473 - f1_m: 0.8349 - precision_m: 0.8857 - recall_m: 0.8032 - val_loss: 0.4237 - val_acc: 0.8719 - val_f1_m: 0.8711 - val_precision_m: 0.8848 - val_recall_m: 0.8583\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.41591\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 9s 96ms/step - loss: 0.3769 - acc: 0.8606 - f1_m: 0.8400 - precision_m: 0.8863 - recall_m: 0.8053 - val_loss: 0.4236 - val_acc: 0.8774 - val_f1_m: 0.8777 - val_precision_m: 0.8921 - val_recall_m: 0.8642\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.41591\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.3220 - acc: 0.8894 - f1_m: 0.8859 - precision_m: 0.9218 - recall_m: 0.8554 - val_loss: 0.4648 - val_acc: 0.8501 - val_f1_m: 0.8511 - val_precision_m: 0.8689 - val_recall_m: 0.8349\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.41591\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.3625 - acc: 0.8660 - f1_m: 0.8479 - precision_m: 0.8788 - recall_m: 0.8224 - val_loss: 0.4139 - val_acc: 0.8774 - val_f1_m: 0.8806 - val_precision_m: 0.8926 - val_recall_m: 0.8691\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.41591 to 0.41393, saving model to ./model/model-012-0.865804-0.413929.h5\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 9s 94ms/step - loss: 0.3543 - acc: 0.8607 - f1_m: 0.8423 - precision_m: 0.8802 - recall_m: 0.8164 - val_loss: 0.4183 - val_acc: 0.8719 - val_f1_m: 0.8683 - val_precision_m: 0.8817 - val_recall_m: 0.8557\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.41393\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 9s 96ms/step - loss: 0.3246 - acc: 0.8819 - f1_m: 0.8712 - precision_m: 0.9147 - recall_m: 0.8425 - val_loss: 0.4376 - val_acc: 0.8747 - val_f1_m: 0.8799 - val_precision_m: 0.8908 - val_recall_m: 0.8694\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.41393\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.3347 - acc: 0.8775 - f1_m: 0.8550 - precision_m: 0.8874 - recall_m: 0.8311 - val_loss: 0.4328 - val_acc: 0.8774 - val_f1_m: 0.8731 - val_precision_m: 0.8828 - val_recall_m: 0.8639\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.41393\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.3370 - acc: 0.8644 - f1_m: 0.8477 - precision_m: 0.8791 - recall_m: 0.8259 - val_loss: 0.4433 - val_acc: 0.8719 - val_f1_m: 0.8794 - val_precision_m: 0.8906 - val_recall_m: 0.8691\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.41393\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.2668 - acc: 0.9087 - f1_m: 0.8990 - precision_m: 0.9306 - recall_m: 0.8760 - val_loss: 0.4656 - val_acc: 0.8638 - val_f1_m: 0.8732 - val_precision_m: 0.8888 - val_recall_m: 0.8587\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.41393\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.2516 - acc: 0.9174 - f1_m: 0.9078 - precision_m: 0.9362 - recall_m: 0.8858 - val_loss: 0.4719 - val_acc: 0.8692 - val_f1_m: 0.8752 - val_precision_m: 0.8895 - val_recall_m: 0.8616\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.41393\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 9s 96ms/step - loss: 0.2856 - acc: 0.9027 - f1_m: 0.9009 - precision_m: 0.9317 - recall_m: 0.8770 - val_loss: 0.4459 - val_acc: 0.8638 - val_f1_m: 0.8624 - val_precision_m: 0.8715 - val_recall_m: 0.8535\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.41393\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.2613 - acc: 0.9048 - f1_m: 0.8945 - precision_m: 0.9205 - recall_m: 0.8768 - val_loss: 0.4494 - val_acc: 0.8747 - val_f1_m: 0.8756 - val_precision_m: 0.8853 - val_recall_m: 0.8665\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.41393\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.3506 - acc: 0.8699 - f1_m: 0.8496 - precision_m: 0.9191 - recall_m: 0.8247 - val_loss: 0.4530 - val_acc: 0.8638 - val_f1_m: 0.8701 - val_precision_m: 0.8879 - val_recall_m: 0.8535\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.41393\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.2467 - acc: 0.9151 - f1_m: 0.9078 - precision_m: 0.9372 - recall_m: 0.8904 - val_loss: 0.4437 - val_acc: 0.8692 - val_f1_m: 0.8740 - val_precision_m: 0.8846 - val_recall_m: 0.8639\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.41393\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.2605 - acc: 0.9158 - f1_m: 0.9012 - precision_m: 0.9422 - recall_m: 0.8781 - val_loss: 0.4692 - val_acc: 0.8638 - val_f1_m: 0.8699 - val_precision_m: 0.8881 - val_recall_m: 0.8531\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.41393\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.2637 - acc: 0.9048 - f1_m: 0.8889 - precision_m: 0.9122 - recall_m: 0.8701 - val_loss: 0.4641 - val_acc: 0.8692 - val_f1_m: 0.8697 - val_precision_m: 0.8815 - val_recall_m: 0.8587\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.41393\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.2972 - acc: 0.8918 - f1_m: 0.8671 - precision_m: 0.8870 - recall_m: 0.8498 - val_loss: 0.4850 - val_acc: 0.8610 - val_f1_m: 0.8675 - val_precision_m: 0.8791 - val_recall_m: 0.8564\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.41393\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.2225 - acc: 0.9287 - f1_m: 0.9215 - precision_m: 0.9547 - recall_m: 0.9055 - val_loss: 0.4912 - val_acc: 0.8447 - val_f1_m: 0.8539 - val_precision_m: 0.8655 - val_recall_m: 0.8431\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.41393\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.3197 - acc: 0.8791 - f1_m: 0.8514 - precision_m: 0.8768 - recall_m: 0.8320 - val_loss: 0.4903 - val_acc: 0.8610 - val_f1_m: 0.8718 - val_precision_m: 0.8826 - val_recall_m: 0.8616\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.41393\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 9s 96ms/step - loss: 0.3458 - acc: 0.8637 - f1_m: 0.8360 - precision_m: 0.8925 - recall_m: 0.8158 - val_loss: 0.4808 - val_acc: 0.8665 - val_f1_m: 0.8686 - val_precision_m: 0.8843 - val_recall_m: 0.8538\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.41393\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.2263 - acc: 0.9209 - f1_m: 0.9127 - precision_m: 0.9364 - recall_m: 0.8936 - val_loss: 0.4743 - val_acc: 0.8747 - val_f1_m: 0.8791 - val_precision_m: 0.8948 - val_recall_m: 0.8642\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.41393\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 9s 94ms/step - loss: 0.2691 - acc: 0.9077 - f1_m: 0.8991 - precision_m: 0.9327 - recall_m: 0.8747 - val_loss: 0.4795 - val_acc: 0.8801 - val_f1_m: 0.8834 - val_precision_m: 0.8960 - val_recall_m: 0.8717\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.41393\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.3408 - acc: 0.8706 - f1_m: 0.8461 - precision_m: 0.8804 - recall_m: 0.8252 - val_loss: 0.4722 - val_acc: 0.8692 - val_f1_m: 0.8669 - val_precision_m: 0.8728 - val_recall_m: 0.8613\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.41393\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.1898 - acc: 0.9350 - f1_m: 0.9284 - precision_m: 0.9472 - recall_m: 0.9134 - val_loss: 0.5196 - val_acc: 0.8665 - val_f1_m: 0.8627 - val_precision_m: 0.8787 - val_recall_m: 0.8479\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.41393\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.2495 - acc: 0.9142 - f1_m: 0.8997 - precision_m: 0.9263 - recall_m: 0.8785 - val_loss: 0.5179 - val_acc: 0.8665 - val_f1_m: 0.8676 - val_precision_m: 0.8769 - val_recall_m: 0.8587\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.41393\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.2197 - acc: 0.9232 - f1_m: 0.9164 - precision_m: 0.9366 - recall_m: 0.9013 - val_loss: 0.5064 - val_acc: 0.8747 - val_f1_m: 0.8646 - val_precision_m: 0.8742 - val_recall_m: 0.8557\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.41393\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.2466 - acc: 0.9109 - f1_m: 0.8833 - precision_m: 0.9025 - recall_m: 0.8690 - val_loss: 0.5142 - val_acc: 0.8665 - val_f1_m: 0.8571 - val_precision_m: 0.8640 - val_recall_m: 0.8505\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.41393\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.2768 - acc: 0.9005 - f1_m: 0.8770 - precision_m: 0.9200 - recall_m: 0.8592 - val_loss: 0.5466 - val_acc: 0.8610 - val_f1_m: 0.8524 - val_precision_m: 0.8627 - val_recall_m: 0.8427\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.41393\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 9s 96ms/step - loss: 0.3538 - acc: 0.8566 - f1_m: 0.8295 - precision_m: 0.8756 - recall_m: 0.8079 - val_loss: 0.4996 - val_acc: 0.8665 - val_f1_m: 0.8698 - val_precision_m: 0.8793 - val_recall_m: 0.8609\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.41393\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 9s 96ms/step - loss: 0.2364 - acc: 0.9149 - f1_m: 0.9113 - precision_m: 0.9357 - recall_m: 0.8925 - val_loss: 0.5263 - val_acc: 0.8665 - val_f1_m: 0.8669 - val_precision_m: 0.8729 - val_recall_m: 0.8613\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.41393\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 9s 96ms/step - loss: 0.1553 - acc: 0.9502 - f1_m: 0.9430 - precision_m: 0.9583 - recall_m: 0.9325 - val_loss: 0.5494 - val_acc: 0.8501 - val_f1_m: 0.8547 - val_precision_m: 0.8615 - val_recall_m: 0.8483\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.41393\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 9s 96ms/step - loss: 0.2624 - acc: 0.8940 - f1_m: 0.8694 - precision_m: 0.8832 - recall_m: 0.8590 - val_loss: 0.5252 - val_acc: 0.8610 - val_f1_m: 0.8597 - val_precision_m: 0.8666 - val_recall_m: 0.8531\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.41393\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 9s 96ms/step - loss: 0.2856 - acc: 0.8892 - f1_m: 0.8609 - precision_m: 0.9078 - recall_m: 0.8468 - val_loss: 0.5332 - val_acc: 0.8665 - val_f1_m: 0.8577 - val_precision_m: 0.8657 - val_recall_m: 0.8502\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.41393\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 9s 96ms/step - loss: 0.1314 - acc: 0.9539 - f1_m: 0.9517 - precision_m: 0.9589 - recall_m: 0.9455 - val_loss: 0.5284 - val_acc: 0.8610 - val_f1_m: 0.8577 - val_precision_m: 0.8685 - val_recall_m: 0.8476\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.41393\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.2504 - acc: 0.9125 - f1_m: 0.8977 - precision_m: 0.9334 - recall_m: 0.8788 - val_loss: 0.5123 - val_acc: 0.8719 - val_f1_m: 0.8727 - val_precision_m: 0.8819 - val_recall_m: 0.8639\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.41393\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 9s 96ms/step - loss: 0.1959 - acc: 0.9338 - f1_m: 0.9138 - precision_m: 0.9477 - recall_m: 0.8987 - val_loss: 0.4995 - val_acc: 0.8774 - val_f1_m: 0.8780 - val_precision_m: 0.8874 - val_recall_m: 0.8691\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.41393\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 9s 96ms/step - loss: 0.2389 - acc: 0.9091 - f1_m: 0.8941 - precision_m: 0.9471 - recall_m: 0.8761 - val_loss: 0.5501 - val_acc: 0.8529 - val_f1_m: 0.8578 - val_precision_m: 0.8623 - val_recall_m: 0.8535\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.41393\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 9s 96ms/step - loss: 0.2600 - acc: 0.8945 - f1_m: 0.8733 - precision_m: 0.8933 - recall_m: 0.8595 - val_loss: 0.4908 - val_acc: 0.8665 - val_f1_m: 0.8651 - val_precision_m: 0.8721 - val_recall_m: 0.8583\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.41393\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.1604 - acc: 0.9461 - f1_m: 0.9425 - precision_m: 0.9588 - recall_m: 0.9287 - val_loss: 0.5191 - val_acc: 0.8665 - val_f1_m: 0.8633 - val_precision_m: 0.8714 - val_recall_m: 0.8557\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.41393\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.1659 - acc: 0.9371 - f1_m: 0.9299 - precision_m: 0.9457 - recall_m: 0.9211 - val_loss: 0.5241 - val_acc: 0.8665 - val_f1_m: 0.8586 - val_precision_m: 0.8666 - val_recall_m: 0.8509\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.41393\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.1965 - acc: 0.9311 - f1_m: 0.9215 - precision_m: 0.9588 - recall_m: 0.9035 - val_loss: 0.5339 - val_acc: 0.8638 - val_f1_m: 0.8652 - val_precision_m: 0.8722 - val_recall_m: 0.8587\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.41393\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 9s 96ms/step - loss: 0.1461 - acc: 0.9512 - f1_m: 0.9498 - precision_m: 0.9668 - recall_m: 0.9367 - val_loss: 0.5364 - val_acc: 0.8638 - val_f1_m: 0.8622 - val_precision_m: 0.8691 - val_recall_m: 0.8557\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.41393\n"
     ]
    }
   ],
   "source": [
    "# Creamos el modelo desde el pre-trained model MobileNet V2\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                              include_top=False, \n",
    "                                              weights='imagenet')\n",
    "base_model.trainable = False #congelamos los pesos, el extractor de caracteristicas no lo vamos a entrenar\n",
    "\n",
    "#generamos nuestra arquitecture\n",
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.GlobalAveragePooling2D(),\n",
    "#   tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.0001), \n",
    "             # loss='sparse_categorical_crossentropy', \n",
    "               loss='categorical_crossentropy', \n",
    "#              metrics=['accuracy']\n",
    "             metrics=['acc',f1_m,precision_m, recall_m])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "EPOCHS = 50\n",
    "\n",
    "checkpoint = ModelCheckpoint('./model/model-{epoch:03d}-{acc:03f}-{val_loss:03f}.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')  \n",
    "\n",
    "#history = model.fit(train, validation_data=validation, batch_size=BATCH_SIZE, callbacks=[checkpoint], epochs=30)    \n",
    "\n",
    "history = model.fit(train, \n",
    "                    callbacks = [checkpoint],\n",
    "                    epochs=EPOCHS, \n",
    "                    validation_data=validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-turtle",
   "metadata": {},
   "source": [
    "He realizado varios experimentos probando diferentes epochs, learning rates, capas de convoluciones o regularizaciones.\n",
    "\n",
    "En \"trainmobilNetv2+dense.png\" se puede encontrar una imagen de un entrenamiento en el que sólo he usado el extractor de características y la dense layer. Se puede observar como a partir de cierto momento se produce un overfitting. Ese efector observado me ha llevado a añadir más capas al modelo para regularizar. En los resultados que se exponen a continuación se puede ver como efectivamente hemos mejorado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "widespread-fantasy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.callbacks.History object at 0x7f597bec72b0>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history)\n",
    "\n",
    "# Plot history: MAE\n",
    "plt.plot(history.history['loss'], label='MAE (training data)')\n",
    "plt.plot(history.history['val_loss'], label='MAE (validation data)')\n",
    "plt.title('MAE for ADVIZ')\n",
    "plt.ylabel('MAE value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "954a9af8-54df-4ae9-bf81-b30a0bfc071b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 63ms/step - loss: 0.4709 - acc: 0.8638 - f1_m: 0.8642 - precision_m: 0.8699 - recall_m: 0.8587\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-venue",
   "metadata": {},
   "source": [
    "Los pasos escogidos me han llevado a un accuracy del 87% en clasificación en test.\n",
    "\n",
    "Mejoras:\n",
    "--\n",
    "Estos resultados Si hubiera tenido más tiempo y recursos hubiera:\n",
    "- usado un modelo más potente al mobilNetV2 como extractor de características (ResNext por ejemplo). Hoy en día los transformers están revolucionando el mundo del DL, en cambio son muy costosos en cuanto a cómputos y realmente sacan partido de sus ventajas en paralelización cuando se disponen de varios nodos de computación donde se puedan ejecutar. Como no es mi caso, yo no los uso.\n",
    "- probado con más métodos de data augmentation\n",
    "- incluido la generación de imágenes adversariales en los conjuntos de datos para que la red aprenda a detectarlos bien\n",
    "- usado más la regularización así como otros parámetros de entrenamiento\n",
    "- hecho un estudio del conjunto de test más exhaustivo como por ejemplo pintar la matriz de confusión, aplicar un cross validation con unas 5 folds.\n",
    "- usar los modelo intermedios (generados en la carpeta model) con el checkpoint para comprobar si efectivamente son mejores estudiando su comportamiento en el conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-morocco",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
